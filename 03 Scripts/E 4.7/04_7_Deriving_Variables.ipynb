{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd11e9b7-21c3-4c0c-adfe-ec8ccd2cf308",
   "metadata": {},
   "source": [
    "# Step 1: Exercise for creating the “price_label” and “busiest_day” columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7c0025-c6eb-4f7f-9c3c-d5b09df78d5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Documents/15-01-2025 Instacart Basket Analysis/02 Data/Prepared Data/ords_prods_merge.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m prepared_data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(project_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02 Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrepared Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the ords_prods_merge dataframe\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m ords_prods_merge \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(prepared_data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mords_prods_merge.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Confirm the data was loaded successfully\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(ords_prods_merge\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    186\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    188\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    189\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    191\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Documents/15-01-2025 Instacart Basket Analysis/02 Data/Prepared Data/ords_prods_merge.pkl'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "project_path = r'/Documents/15-01-2025 Instacart Basket Analysis'\n",
    "prepared_data_path = os.path.join(project_path, '02 Data', 'Prepared Data')\n",
    "\n",
    "# Load the ords_prods_merge dataframe\n",
    "ords_prods_merge = pd.read_pickle(os.path.join(prepared_data_path, 'ords_prods_merge.pkl'))\n",
    "\n",
    "# Confirm the data was loaded successfully\n",
    "print(ords_prods_merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b1d33e-5050-4336-9ae8-851e0e6122b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id  order_number  order_day_of_week  order_hour_of_day  \\\n",
      "0   2539329        1             1                  2                  8   \n",
      "1   2539329        1             1                  2                  8   \n",
      "2   2539329        1             1                  2                  8   \n",
      "3   2539329        1             1                  2                  8   \n",
      "4   2539329        1             1                  2                  8   \n",
      "\n",
      "   days_since_prior_order product_id  add_to_cart_order  reordered  \\\n",
      "0                     NaN        196                  1          0   \n",
      "1                     NaN      14084                  2          0   \n",
      "2                     NaN      12427                  3          0   \n",
      "3                     NaN      26088                  4          0   \n",
      "4                     NaN      26405                  5          0   \n",
      "\n",
      "                              product_name  aisle_id  department_id  prices  \n",
      "0                                     Soda        77              7     9.0  \n",
      "1  Organic Unsweetened Vanilla Almond Milk        91             16    12.5  \n",
      "2                      Original Beef Jerky        23             19     4.4  \n",
      "3               Aged White Cheddar Popcorn        23             19     4.7  \n",
      "4         XL Pick-A-Size Paper Towel Rolls        54             17     1.0  \n"
     ]
    }
   ],
   "source": [
    "# Direct absolute path to the file\n",
    "ords_prods_merge = pd.read_pickle('/Users/dela/Documents/15-01-2025 Instacart Basket Analysis/02 Data/Prepared Data/ords_prods_merge.pkl')\n",
    "\n",
    "# Verify the data was loaded\n",
    "print(ords_prods_merge.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f897dcb-e6a7-445d-bfa8-3b4780dbcef7",
   "metadata": {},
   "source": [
    "# Create a subset of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0655852-23ed-4350-9a68-4b31ae17d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the dataframe with the first 1,000,000 rows\n",
    "df_subset = ords_prods_merge[:1000000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5bd60-dc4d-4c9c-bdbe-7bef554968c0",
   "metadata": {},
   "source": [
    "# Apply the price_label Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8bff768-bd85-4865-abaa-45c619620915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the price_label function\n",
    "def price_label(row):\n",
    "    if row['prices'] <= 5:\n",
    "        return 'Low-range product'\n",
    "    elif (row['prices'] > 5) and (row['prices'] <= 15):\n",
    "        return 'Mid-range product'\n",
    "    elif row['prices'] > 15:\n",
    "        return 'High-range product'\n",
    "    else:\n",
    "        return 'Not enough data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae73887a-a048-4769-ae70-3a4300299927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_label\n",
      "Mid-range product     673189\n",
      "Low-range product     314386\n",
      "High-range product     12425\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/vlcc2lxn4d7cl51gd3xv8gwh0000gn/T/ipykernel_4379/2198804588.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset['price_label'] = df_subset.apply(price_label, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Apply the price_label function to the subset\n",
    "df_subset['price_label'] = df_subset.apply(price_label, axis=1)\n",
    "\n",
    "# Check the new column\n",
    "print(df_subset['price_label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ad30231-e176-4f6c-9cd8-40ffc7120999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_label\n",
      "Mid-range product     673189\n",
      "Low-range product     314386\n",
      "High-range product     12425\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of the dataframe with the first 1,000,000 rows\n",
    "df_subset = ords_prods_merge[:1000000].copy()\n",
    "\n",
    "# Apply the price_label function to the subset\n",
    "df_subset['price_label'] = df_subset.apply(price_label, axis=1)\n",
    "\n",
    "# Check the new column\n",
    "print(df_subset['price_label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb12617-614d-46d0-b986-c1ef0dc8bf82",
   "metadata": {},
   "source": [
    "# Create the busiest_day Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a6e8a3-f47a-4c62-839a-c93a17fc4df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busiest_day\n",
      "Regularly busy    692458\n",
      "Busiest day       189674\n",
      "Least busy        117868\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store results\n",
    "result = []\n",
    "\n",
    "# Loop through the 'order_day_of_week' column and assign labels\n",
    "for value in df_subset['order_day_of_week']:\n",
    "    if value == 0:  # Saturday\n",
    "        result.append(\"Busiest day\")\n",
    "    elif value == 4:  # Wednesday\n",
    "        result.append(\"Least busy\")\n",
    "    else:\n",
    "        result.append(\"Regularly busy\")\n",
    "\n",
    "# Add the list to the dataframe as a new column\n",
    "df_subset['busiest_day'] = result\n",
    "\n",
    "# Check the value counts of the new column\n",
    "print(df_subset['busiest_day'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c382aaa-e811-444d-a5a7-0556e50d8bc5",
   "metadata": {},
   "source": [
    "# Compare Alternatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a4e6615-0457-463c-bd02-41003c11e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busiest_day\n",
      "Regularly busy    692458\n",
      "Busiest day       189674\n",
      "Least busy        117868\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the conditions and assign labels\n",
    "df_subset.loc[df_subset['order_day_of_week'] == 0, 'busiest_day'] = \"Busiest day\"\n",
    "df_subset.loc[df_subset['order_day_of_week'] == 4, 'busiest_day'] = \"Least busy\"\n",
    "df_subset.loc[(df_subset['order_day_of_week'] != 0) & (df_subset['order_day_of_week'] != 4), 'busiest_day'] = \"Regularly busy\"\n",
    "\n",
    "# Check the value counts of the new column\n",
    "print(df_subset['busiest_day'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86229ba2-17ab-4b51-95da-3734176c8d99",
   "metadata": {},
   "source": [
    "# Remove the Subset and Use the Full Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9654da0-5884-4c85-86e7-f93b5d3f9b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id  order_number  order_day_of_week  order_hour_of_day  \\\n",
      "0   2539329        1             1                  2                  8   \n",
      "1   2539329        1             1                  2                  8   \n",
      "2   2539329        1             1                  2                  8   \n",
      "3   2539329        1             1                  2                  8   \n",
      "4   2539329        1             1                  2                  8   \n",
      "\n",
      "   days_since_prior_order product_id  add_to_cart_order  reordered  \\\n",
      "0                     NaN        196                  1          0   \n",
      "1                     NaN      14084                  2          0   \n",
      "2                     NaN      12427                  3          0   \n",
      "3                     NaN      26088                  4          0   \n",
      "4                     NaN      26405                  5          0   \n",
      "\n",
      "                              product_name  aisle_id  department_id  prices  \n",
      "0                                     Soda        77              7     9.0  \n",
      "1  Organic Unsweetened Vanilla Almond Milk        91             16    12.5  \n",
      "2                      Original Beef Jerky        23             19     4.4  \n",
      "3               Aged White Cheddar Popcorn        23             19     4.7  \n",
      "4         XL Pick-A-Size Paper Towel Rolls        54             17     1.0  \n"
     ]
    }
   ],
   "source": [
    "# Reload the full dataframe\n",
    "ords_prods_merge = pd.read_pickle('/Users/dela/Documents/15-01-2025 Instacart Basket Analysis/02 Data/Prepared Data/ords_prods_merge.pkl')\n",
    "\n",
    "# Confirm the data loaded successfully\n",
    "print(ords_prods_merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64fb0de1-452a-463b-850b-09f50e9f8737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_label\n",
      "Mid-range product     21860852\n",
      "Low-range product     10125759\n",
      "High-range product      417678\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add the 'price_label' column to the full dataframe\n",
    "ords_prods_merge.loc[ords_prods_merge['prices'] <= 5, 'price_label'] = 'Low-range product'\n",
    "ords_prods_merge.loc[(ords_prods_merge['prices'] > 5) & (ords_prods_merge['prices'] <= 15), 'price_label'] = 'Mid-range product'\n",
    "ords_prods_merge.loc[ords_prods_merge['prices'] > 15, 'price_label'] = 'High-range product'\n",
    "\n",
    "# Check the distribution of the new column\n",
    "print(ords_prods_merge['price_label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c3f0f76-c72e-4a9a-81d3-0b72a6b9eee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busiest_day\n",
      "Regularly busy    22416495\n",
      "Busiest day        6204040\n",
      "Least busy         3783754\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add the 'busiest_day' column to the full dataframe\n",
    "ords_prods_merge.loc[ords_prods_merge['order_day_of_week'] == 0, 'busiest_day'] = 'Busiest day'\n",
    "ords_prods_merge.loc[ords_prods_merge['order_day_of_week'] == 4, 'busiest_day'] = 'Least busy'\n",
    "ords_prods_merge.loc[(ords_prods_merge['order_day_of_week'] != 0) & \n",
    "                     (ords_prods_merge['order_day_of_week'] != 4), 'busiest_day'] = 'Regularly busy'\n",
    "\n",
    "# Check the distribution of the new column\n",
    "print(ords_prods_merge['busiest_day'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e8b56-c526-4be9-ba46-69e0c915b720",
   "metadata": {},
   "source": [
    "# Verify the Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b46c7a0-3ee7-44de-bdd0-c9399e1addc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id  order_number  order_day_of_week  order_hour_of_day  \\\n",
      "0   2539329        1             1                  2                  8   \n",
      "1   2539329        1             1                  2                  8   \n",
      "2   2539329        1             1                  2                  8   \n",
      "3   2539329        1             1                  2                  8   \n",
      "4   2539329        1             1                  2                  8   \n",
      "\n",
      "   days_since_prior_order product_id  add_to_cart_order  reordered  \\\n",
      "0                     NaN        196                  1          0   \n",
      "1                     NaN      14084                  2          0   \n",
      "2                     NaN      12427                  3          0   \n",
      "3                     NaN      26088                  4          0   \n",
      "4                     NaN      26405                  5          0   \n",
      "\n",
      "                              product_name  aisle_id  department_id  prices  \\\n",
      "0                                     Soda        77              7     9.0   \n",
      "1  Organic Unsweetened Vanilla Almond Milk        91             16    12.5   \n",
      "2                      Original Beef Jerky        23             19     4.4   \n",
      "3               Aged White Cheddar Popcorn        23             19     4.7   \n",
      "4         XL Pick-A-Size Paper Towel Rolls        54             17     1.0   \n",
      "\n",
      "         price_label     busiest_day  \n",
      "0  Mid-range product  Regularly busy  \n",
      "1  Mid-range product  Regularly busy  \n",
      "2  Low-range product  Regularly busy  \n",
      "3  Low-range product  Regularly busy  \n",
      "4  Low-range product  Regularly busy  \n",
      "price_label\n",
      "Mid-range product     21860852\n",
      "Low-range product     10125759\n",
      "High-range product      417678\n",
      "Name: count, dtype: int64\n",
      "busiest_day\n",
      "Regularly busy    22416495\n",
      "Busiest day        6204040\n",
      "Least busy         3783754\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ords_prods_merge.head())\n",
    "\n",
    "print(ords_prods_merge['price_label'].value_counts())\n",
    "print(ords_prods_merge['busiest_day'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a5ff445-75c5-4bf6-922a-e283516dd951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataframe to a new pickle file\n",
    "ords_prods_merge.to_pickle('/Users/dela/Documents/15-01-2025 Instacart Basket Analysis/02 Data/Prepared Data/ords_prods_merge_updated.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78d57f-e72d-4d76-9adc-3e9473204a22",
   "metadata": {},
   "source": [
    "# Step 2: Update \"Busiest day\" to \"Busiest days\" and Identify Two Busiest and Two Slowest Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d964fa6d-e407-4ef2-ae73-aa8a507bde74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_day_of_week\n",
      "0    6204040\n",
      "1    5660135\n",
      "6    4496403\n",
      "2    4213760\n",
      "5    4205721\n",
      "3    3840476\n",
      "4    3783754\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the frequency of orders by day\n",
    "day_frequency = ords_prods_merge['order_day_of_week'].value_counts()\n",
    "print(day_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94fa245c-d8e6-4d91-8d82-7d70d92cb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define busiest and slowest days based on the frequency analysis\n",
    "busiest_days = [0, 1]  # Top 2 busiest day indices\n",
    "slowest_days = [4, 5]  # Bottom 2 slowest day indices\n",
    "\n",
    "# Add the new \"busiest_days\" column\n",
    "ords_prods_merge.loc[ords_prods_merge['order_day_of_week'].isin(busiest_days), 'busiest_days'] = 'Busiest days'\n",
    "ords_prods_merge.loc[ords_prods_merge['order_day_of_week'].isin(slowest_days), 'busiest_days'] = 'Slowest days'\n",
    "ords_prods_merge.loc[~ords_prods_merge['order_day_of_week'].isin(busiest_days + slowest_days), 'busiest_days'] = 'Regular days'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889121ac-359f-45ab-a94f-3734a9318d11",
   "metadata": {},
   "source": [
    "# Step 3: Check the Values for Accuracy and Note Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08d43d18-90f3-4d23-b625-186814a4801b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busiest_days\n",
      "Regular days    12550639\n",
      "Busiest days    11864175\n",
      "Slowest days     7989475\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check value counts for the new column\n",
    "print(ords_prods_merge['busiest_days'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8fb3e0-84e2-4515-a657-993dfc57af29",
   "metadata": {},
   "source": [
    "### Observations for Busiest Days\n",
    "\n",
    "#### Value Distribution:\n",
    "- **Regular days:** 12,550,639 rows\n",
    "- **Busiest days:** 11,864,175 rows\n",
    "- **Slowest days:** 7,989,475 rows\n",
    "\n",
    "---\n",
    "\n",
    "#### Accuracy Checks:\n",
    "1. The **busiest days** label has been correctly applied to `order_day_of_week` values of `0` and `1`.\n",
    "2. The **slowest days** label has been correctly applied to `order_day_of_week` values of `4` and `5`.\n",
    "3. All remaining rows are labeled as **regular days**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Trends Observed:\n",
    "1. **Busiest Days:** Account for **37%** of the data.\n",
    "2. **Slowest Days:** Represent **25%** of the data.\n",
    "3. **Regular Days:** Comprise the remaining **38%**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Insights:\n",
    "1. **Marketing Opportunities:** Focus promotions on **regular days**.\n",
    "2. **Operational Planning:** Prepare for high demand on the busiest days.\n",
    "3. **Customer Behavior:** Midweek slowdowns might align with customer work schedules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58887b09-3a2d-4fe2-a38a-aed6584ce87e",
   "metadata": {},
   "source": [
    "# step 4 : Label Busiest Periods of the Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcea9317-c396-4855-9ad8-411e03f27435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_hour_of_day\n",
      "0      218766\n",
      "1      115699\n",
      "2       69374\n",
      "3       51281\n",
      "4       53241\n",
      "5       87959\n",
      "6      290492\n",
      "7      891040\n",
      "8     1718100\n",
      "9     2454165\n",
      "10    2761710\n",
      "11    2736075\n",
      "12    2618481\n",
      "13    2660900\n",
      "14    2689086\n",
      "15    2662094\n",
      "16    2535154\n",
      "17    2087609\n",
      "18    1636469\n",
      "19    1258290\n",
      "20     976145\n",
      "21     795628\n",
      "22     634216\n",
      "23     402315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the frequency of orders by hour\n",
    "hour_frequency = ords_prods_merge['order_hour_of_day'].value_counts().sort_index()\n",
    "print(hour_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ce9d3d4-c25d-4523-ae94-159197f78e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate thresholds\n",
    "q25 = hour_frequency.quantile(0.25)  # Bottom 25%\n",
    "q75 = hour_frequency.quantile(0.75)  # Top 25%\n",
    "\n",
    "# Define the hours for each category\n",
    "most_order_hours = hour_frequency[hour_frequency >= q75].index.tolist()\n",
    "fewest_order_hours = hour_frequency[hour_frequency <= q25].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "817718cd-f981-42eb-8f16-52c6f7fd4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"busiest_period_of_day\" column\n",
    "ords_prods_merge.loc[ords_prods_merge['order_hour_of_day'].isin(most_order_hours), 'busiest_period_of_day'] = 'Most orders'\n",
    "ords_prods_merge.loc[ords_prods_merge['order_hour_of_day'].isin(fewest_order_hours), 'busiest_period_of_day'] = 'Fewest orders'\n",
    "ords_prods_merge.loc[~ords_prods_merge['order_hour_of_day'].isin(most_order_hours + fewest_order_hours), 'busiest_period_of_day'] = 'Average orders'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe6f41-9063-41e6-be29-bc08b19ab9cb",
   "metadata": {},
   "source": [
    "# step5 : Print the frequency for this new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72370198-5cf5-494d-80ab-eb3da9fe7d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busiest_period_of_day\n",
      "Most orders       16128346\n",
      "Average orders    15679623\n",
      "Fewest orders       596320\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the frequency of the 'busiest_period_of_day' column\n",
    "print(ords_prods_merge['busiest_period_of_day'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273db970-d40b-4e01-988f-89decfb3385c",
   "metadata": {},
   "source": [
    "# Step 7: Export the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47ffe92f-6014-4f0d-85b5-b0da8ef7ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved successfully as ords_prods_merge_updated_v2.pkl in the Prepared Data folder!\n"
     ]
    }
   ],
   "source": [
    "# Define the export path\n",
    "export_path = '/Users/dela/Documents/15-01-2025 Instacart Basket Analysis/02 Data/Prepared Data'\n",
    "\n",
    "# Save the updated dataframe as a new version to avoid overwriting the existing file\n",
    "ords_prods_merge.to_pickle(f'{export_path}/ords_prods_merge_updated_v2.pkl')\n",
    "\n",
    "print(\"Dataframe saved successfully as ords_prods_merge_updated_v2.pkl in the Prepared Data folder!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bcd67-5e7b-473b-b7ef-dc726541008a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
